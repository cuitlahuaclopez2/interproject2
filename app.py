import streamlit as st
import google.generativeai as genai
from PyPDF2 import PdfReader
import os

# --- CONFIGURACI√ìN DE P√ÅGINA ---
st.set_page_config(page_title="Asistente Virtual Experto", page_icon="üìö")
st.title("ü§ñ Consultas al Experto")
st.info("Este chat responde basado exclusivamente en nuestra base de conocimientos oficial.")

# --- CONEXI√ìN CON GEMINI ---
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.error("Error: Configura la API Key en los Secrets de Streamlit.")
    st.stop()

# --- FUNCI√ìN PARA CARGAR DOCUMENTOS DEL SERVIDOR ---
@st.cache_resource # Esto hace que solo lea los archivos UNA vez (ahorra tiempo y dinero)
def cargar_base_conocimiento():
    texto_total = ""
    ruta_docs = "documentos" # Nombre de la carpeta en GitHub
    
    if os.path.exists(ruta_docs):
        archivos = [f for f in os.listdir(ruta_docs) if f.endswith('.pdf')]
        for archivo in archivos:
            try:
                path = os.path.join(ruta_docs, archivo)
                reader = PdfReader(path)
                for page in reader.pages:
                    texto_total += page.extract_text()
            except Exception as e:
                st.error(f"Error leyendo {archivo}: {e}")
    return texto_total

# Cargamos el conocimiento del administrador
contexto_maestro = cargar_base_conocimiento()

if not contexto_maestro:
    st.warning("‚ö†Ô∏è El administrador a√∫n no ha subido documentos a la carpeta 'documentos'.")
    st.stop()

# --- L√ìGICA DEL CHAT ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mostrar historial
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Entrada del usuario
if pregunta := st.chat_input("Haz tu pregunta aqu√≠..."):
    st.session_state.messages.append({"role": "user", "content": pregunta})
    with st.chat_message("user"):
        st.markdown(pregunta)

    # Respuesta de Gemini
    with st.chat_message("assistant"):
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        # El "System Prompt" es lo m√°s importante aqu√≠
        prompt_final = f"""
        Eres un asistente oficial y profesional. 
        Tu conocimiento se limita ESTRICTAMENTE al texto que se te proporciona a continuaci√≥n.
        Si la respuesta no est√° en el texto, responde educadamente que no tienes esa informaci√≥n.
        
        CONOCIMIENTO OFICIAL:
        {contexto_maestro}
        
        PREGUNTA DEL USUARIO:
        {pregunta}
        """
        
        try:
            response = model.generate_content(prompt_final)
            st.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            st.error(f"Error: {e}")
